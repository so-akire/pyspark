{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods Consulting Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dog food company tries to predict why some batches of the dog food are spoiling much quicker than intended!\n",
    "Unfortunately this Dog Food company hasn't upgraded to the latest machinery, meaning that the amounts \n",
    "of the five preservative chemicals they are using can vary a lot, \n",
    "but which is the chemical that has the strongest effect? \n",
    "The dog food company first mixes up a batch of preservative that\n",
    "contains4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. \n",
    "The food scientists beliEve one of the A,B,C, or D preservatives is causing the problem, \n",
    "but need help to figure out which one.\n",
    "Using RF to find out which parameter had the most predicitive power, thus finding out which chemical \n",
    "causes the early spoiling.\n",
    "\n",
    "* A : Percentage of preservative A in the mix\n",
    "* B : Percentage of preservative B in the mix\n",
    "* C : Percentage of preservative C in the mix\n",
    "* D : Percentage of preservative D in the mix\n",
    "* Spoiled: Label indicating whether or not the dog food batch was spoiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('dogfood').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('dog_food.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|                 A|                 B|                 C|                 D|            Spoiled|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|               490|               490|               490|               490|                490|\n",
      "|   mean|  5.53469387755102| 5.504081632653061| 9.126530612244897| 5.579591836734694| 0.2857142857142857|\n",
      "| stddev|2.9515204234399057|2.8537966089662063|2.0555451971054275|2.8548369309982857|0.45221563164613465|\n",
      "|    min|                 1|                 1|               5.0|                 1|                0.0|\n",
      "|    max|                10|                10|              14.0|                10|                1.0|\n",
      "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+\n",
      "|  A|  B|   C|  D|Spoiled|\n",
      "+---+---+----+---+-------+\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "|  5|  6|12.0|  7|    1.0|\n",
      "|  6|  2|13.0|  6|    1.0|\n",
      "|  4|  2|12.0|  1|    1.0|\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "+---+---+----+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('C',data['C'].cast(IntegerType()))\n",
    "data = data.withColumn('Spoiled',data['Spoiled'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-------+\n",
      "|  A|  B|  C|  D|Spoiled|\n",
      "+---+---+---+---+-------+\n",
      "|  4|  2| 12|  3|      1|\n",
      "|  5|  6| 12|  7|      1|\n",
      "|  6|  2| 13|  6|      1|\n",
      "|  4|  2| 12|  1|      1|\n",
      "|  4|  2| 12|  3|      1|\n",
      "+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'Spoiled']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['A', 'B', 'C', 'D'],\n",
    "                           outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD, testD = output.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol = 'Spoiled', featuresCol = 'features')\n",
    "rfc = RandomForestClassifier(labelCol='Spoiled',featuresCol='features')\n",
    "gbt = GBTClassifier(labelCol='Spoiled',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(trainD)\n",
    "rfc_model = rfc.fit(trainD)\n",
    "gbt_model = gbt.fit(trainD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features which caused early spoiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 0.0257, 1: 0.002, 2: 0.9714, 3: 0.0009})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 0.0222, 1: 0.0213, 2: 0.9378, 3: 0.0187})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 0.0614, 1: 0.0347, 2: 0.8869, 3: 0.017})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(testD)\n",
    "rfc_predictions = rfc_model.transform(testD)\n",
    "gbt_predictions = gbt_model.transform(testD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|spoiled|prediction|\n",
      "+-------+----------+\n",
      "|      1|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      1|       1.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       0.0|\n",
      "|      0|       0.0|\n",
      "|      1|       1.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "|      0|       0.0|\n",
      "+-------+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_predictions.select('spoiled', 'prediction').show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol = 'Spoiled', predictionCol ='prediction', metricName = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "gbt_acc = acc_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "--------------------------------------------------------------------------------\n",
      "A single decision tree had an accuracy of : 95.48%\n",
      "--------------------------------------------------------------------------------\n",
      "A random forest ensemble had an accuracy of:  96.13%\n",
      "--------------------------------------------------------------------------------\n",
      "An ensemble using GBT  had an accuracy of:  95.48%\n"
     ]
    }
   ],
   "source": [
    "print('Results:')\n",
    "print ('-'*80)\n",
    "print ('A single decision tree had an accuracy of : {0:2.2f}%'.format(dtc_acc* 100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble had an accuracy of:  {0:2.2f}%'.format(rfc_acc* 100))\n",
    "print('-'*80)\n",
    "print('An ensemble using GBT  had an accuracy of:  {0:2.2f}%'.format(gbt_acc* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
